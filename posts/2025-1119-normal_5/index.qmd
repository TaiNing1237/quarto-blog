---
title: "一天證明一個 Normal Distribution 的性質 Day5：獨立性的視角 Cumulant"
author: "Tai-Ning Liao"
date: "2025-11-19"
categories: [Normal Distribution]
format:
    html:
        fig-align: center # 這會讓所有圖片都置中
        fig-cap-location: bottom # 確保圖標在圖片下方
        fig-cap-align: center # 這是控制圖標置中的關鍵
---

今天來講個比較輕鬆的小主題：**Cumulant 多項式** 

對於一個隨機變數 $X$，我們通常想知道平均跟標準差。有時候我們甚至會想知道更高階的資訊，例如偏度 (skewness) 跟峰度 (kurtosis)，這些都可以透過動差 (moment) 來描述。

### Cumulant Generating Function 
還記得動差生成函數 (Moment Generating Function, MGF) 定義為：
$$  
M_X(t) = \mathbb{E}[e^{tX}] = \sum_{k=0}^{\infty} \mathbb{E}[X^{k}] \frac{t^k}{k!} 
$$
名符其實，他就是「動差」的生成函數，因為對 $M_X(t)$ 做泰勒展開 (Taylor Expansion) 後，係數正好是各階 **動差** (moment)：
$$
\mu_k' := \mathbb{E}[X^k] = M_X^{(k)}(0) = \left. \frac{d^k}{dt^k} M_X(t) \right|_{t=0}  \tag{1}\label{eq:moment_def_1}
$$
另外一種比較常用的是減掉常數項的**中心動差** (central moment)：
$$
\mu_k := \mathbb{E}[(X - \mathbb{E}[X])^k]
$$

不過呢，有時候因為動差函數不存在 (例如 Cauchy 分佈)，我們會改用一定會存在的特徵函數 (Characteristic Function, CF)：
$$
\phi_X(t) = \mathbb{E}[e^{itX}] = \sum_{k=0}^{\infty} \mathbb{E}[X^{k}] \frac{(it)^k}{k!}
$$
所以也可以用 $\phi_X(t)$ 來計算動差：
$$
\mu_k' = \mathbb{E}[X^k] = \frac{1}{i^k} \phi_X^{(k)}(0) = \left. \frac{1}{i^k} \frac{d^k}{dt^k} \phi_X(t) \right|_{t=0}  \tag{2}\label{eq:moment_def_2}
$$
至於 central moment，
$$
\mu_k = \mathbb{E}[(X - \mathbb{E}[X])^k] = \frac{1}{i^k} \frac{d^k}{dt^k} \left[ e^{-it \mu_1'} \phi_X(t) \right]_{t=0}
$$
這邊要稍微注意一下，CF 是個複數值函數，所以其實是個複變函數的微分!

**舉例說明**：

| Distribution | $\phi_X(t)$ | $\frac{d}{dt}\phi_X(t)$ | $\mathbb{E}[X]$ | $\frac{d^2}{dt^2}\phi_X(t)$ | $\mathbb{E}[X^2]$ |
|------|------------------|-------------------------|----------------------|-----------------------------|---------------------------|
| Bernoulli($p$) | $1 - p + p e^{it}$ | $ip e^{it}$ | $p$ | $-p e^{it}$ | $p$ |
| Poisson($\lambda$) | $e^{\lambda(e^{it}-1)}$ | $i\lambda e^{it} e^{\lambda(e^{it}-1)}$ | $\lambda$ | $-\lambda e^{it} e^{\lambda(e^{it}-1)} + (i\lambda e^{it})^2 e^{\lambda(e^{it}-1)}$ | $\lambda + \lambda^2$ |
| Normal($\mu, \sigma^2$) | $e^{i\mu t - \frac{1}{2}\sigma^2 t^2}$ | $i\mu e^{i\mu t - \frac{1}{2}\sigma^2 t^2} - \sigma^2 t e^{i\mu t - \frac{1}{2}\sigma^2 t^2}$ | $\mu$ | $-\sigma^2 e^{i\mu t - \frac{1}{2}\sigma^2 t^2} + (i\mu - \sigma^2 t)^2 e^{i\mu t - \frac{1}{2}\sigma^2 t^2}$ | $\sigma^2 + \mu^2$ |
| Gamma($\alpha, \theta$) | $(1 - i\theta t)^{-\alpha}$ | $i\alpha \theta (1 - i\theta t)^{-\alpha - 1}$ | $\alpha \theta$ | $- \alpha (\alpha + 1) \theta^2 (1 - i\theta t)^{-\alpha - 2}$ | $\alpha (\alpha + 1) \theta^2$ |

而如果只是想算 moment 的話 CF 就很夠用，但他對於捕捉獨立性 (independence) 的效果並不理想。這時候我們就需要用到 **Cumulant Generating Function (CGF)**：
$$
K_X(t) = \log M_X(t) = \log \mathbb{E}[e^{tX}]  \tag{3}\label{eq:cumulant_gf_def}
$$  
因此我們定義 Cumulant 為：
$$
\kappa_k := K_X^{(k)}(0) = \left. \frac{d^k}{dt^k} K_X(t) \right|_{t=0}  \tag{4}\label{eq:cumulant_def_1}
$$

當然，也有複數版本，通常會叫 Second Characteristic Function：
$$
H_X(t) = \log \phi_X(t) = \log \mathbb{E}[e^{itX}]  \tag{5}\label{eq:second_char_def}
$$
但這有個問題，就是 $\phi_X(t)$ 可能會是負數或複數，導致 $\log \phi_X(t)$ 會有多重值 (multi-valued) 的問題，所以我們通常還是用實數版本的 CGF。

取了 $\log$ 的好處就是：**如果 $X$ 跟 $Y$ 獨立，那麼 $K_{X+Y}(t) = K_X(t) + K_Y(t)$**。這點跟 MGF 不同，因為 MGF 是乘法關係 ($M_{X+Y}(t) = M_X(t) M_Y(t)$)。

所以對於 moment 來說，兩個獨立隨機變數相加的第 $n$ 階動差，會是兩個變數各自前 $n$ 階動差的 convolution (加上一些組合係數)。
但對於 cumulant 來說，兩個獨立隨機變數相加的第 $n$ 階 cumulant，會是兩個變數各自第 $n$ 階 cumulant 的**直接相加**：
$$
\kappa_n(X + Y) = \kappa_n(X) + \kappa_n(Y) \quad \text{if } X \perp Y  \tag{6}\label{eq:cumulant_indep_add}
$$  

**舉例說明**：

| Distribution | $\kappa_1$ | $\kappa_2$ | $\kappa_3$ | $\kappa_4$ |
|------|------------------|-------------------------|----------------------|---------------------------|
| Bernoulli($p$) | $p$ | $p(1-p)$ | $p(1-p)(1-2p)$ | $p(1-p)(1 - 6p(1-p))$ |
| Poisson($\lambda$) | $\lambda$ | $\lambda$ | $\lambda$ | $\lambda$ |
| Normal($\mu, \sigma^2$) | $\mu$ | $\sigma^2$ | $0$ | $0$ |
| Gamma($\alpha, \theta$) | $\alpha \theta$ | $\alpha \theta^2$ | $2 \alpha \theta^3$ | $6 \alpha \theta^4$ |

**註**: 直覺上因為 distribution 完全被 CF 決定，所以知道了所有 moment (或 cumulant) 似乎也就等於知道了 distribution 本身。但是，其實有可能 CF 在 0 點附近並不解析 (analytic)，常見例子請參考 Log-Normal distribution。所以說，知道所有 moment 只是知道在 0 點的微分，並不保證能還原整個 CF。

看著這個表，我們會想，是不是任意給 $\kappa_1, \kappa_2, \ldots, \kappa_n$，就能找到一個對應的分佈？答案是否定的。比方說，若要使 cumulant 只有有限項非零，那麼這個分佈只能是 Normal 分佈，這是個非常有名的結果：

> **大定理(Marcinkiewicz Theorem)**: 如果一個隨機變數的 cumulant generating function 是個(有限階)多項式，那麼這個多項式的階數最多是 2。

為了保證 CGF 的存在性，該定理本來的敘述是說，若 CF 可以寫成 $\phi_X(t) = e^{P(t)}$，其中 $P(t)$ 是個(複係數)多項式，那麼 $P(t)$ 的階數最多是 2。

我們先跳過證明，提供一些直覺上的理解：主要是因為 CF 是 PDF 的傅立葉變換，而 PDF 必須非負 (non-negative)，這使得 CF 的形式受到很大限制。@lukacs1970 [Theorem 7.3.3] 有詳細的證明。


### Cumulant vs Moment 
在一階、二階和三階，cumulant 跟 central moment 是一樣的:
$$
\frac{d}{dt} K_X(t) = \frac{M_X'(t)}{M_X(t)} \implies \kappa_1 = K_X'(0) = M_X'(0) = \mu_1' = \mathbb{E}[X]
$$
$$
\begin{align}
&\frac{d^2}{dt^2} K_X(t) = \frac{M_X''(t)}{M_X(t)} - \frac{M_X'(t)^2}{(M_X(t))^2} \\
\implies &\kappa_2 = K_X''(0) = M_X''(0) - (M_X'(0))^2 = \mu_2' - \mu_1'^2 = \mathbb{E}[(X - \mathbb{E}[X])^2] = \mu_2
\end{align}
$$
三階 cumulant 是：
$$
\begin{align}
&\frac{d^3}{dt^3} K_X(t) = \frac{M_X'''(t)}{M_X(t)} - 3 \frac{M_X''(t) M_X'(t)}{(M_X(t))^2} + 2 \frac{(M_X'(t))^3}{(M_X(t))^3} \\ 
\implies &\kappa_3 = K_X'''(0) = M_X'''(0) - 3 M_X''(0) M_X'(0) + 2 (M_X'(0))^3 \\
&\quad = \mu_3' - 3 \mu_2' \mu_1' + 2 (\mu_1')^3 = \mathbb{E}[(X - \mathbb{E}[X])^3] = \mu_3
\end{align}
$$
但是從四階開始，cumulant 跟 central moment 就不一樣了：
$$
\frac{d^4}{dt^4} K_X(t) = \frac{M_X^{(4)}(t)}{M_X(t)} - 4 \frac{M_X^{(3)}(t) M_X'(t)}{(M_X(t))^2} - 3 \frac{(M_X''(t))^2}{(M_X(t))^2} + 12 \frac{M_X''(t) (M_X'(t))^2}{(M_X(t))^3} - 6 \frac{(M_X'(t))^4}{(M_X(t))^4}
$$
所以我們有：
$$
\begin{align}
\implies &\kappa_4 = K_X^{(4)}(0) = M_X^{(4)}(0) - 4 M_X^{(3)}(0) M_X'(0) - 3 (M_X''(0))^2 + 12 M_X''(0) (M_X'(0))^2 - 6 (M_X'(0))^4 \\
&\quad = \mu_4' - 4 \mu_3' \mu_1' - 3 (\mu_2')^2 + 12 \mu_2' (\mu_1')^2 - 6 (\mu_1')^4 \\
&\quad = \mathbb{E}[(X - \mathbb{E}[X])^4] - 3 (\mathbb{E}[(X - \mathbb{E}[X])^2])^2 = \mu_4 - 3 \mu_2^2
\end{align}
$$

由 cumulant 對於獨立變數相加的可加性質，我們可以由此看出，兩個獨立的隨機變數相加，平均值、變異數、偏度 都會相加，但峰度卻不會相加，因為峰度差了 $3 \mu_2^2$。而一般峰度的定義是 $\text{Kurt}[X] = \frac{\mu_4}{\mu_2^2}$，所以峰度減去 3 (稱之為 excess kurtosis)，再搭配上適當的 variance scaling 就會有可加性。


**一般式的推導**

徒手算到這邊也差不多了。對於更高階的 cumulant，我們應該系統化地研究他們的係數。
因為 $M_X(t) = e^{K_X(t)}$，所以 $\frac{dM_X(t)}{dt} = K_X'(t) e^{K_X(t)} = K_X'(t) M_X(t)$。

> 乘法的微分 $n$ 階就會跟 二項式係數 有關:
$$
\frac{d^n}{dt^n} [f(t) g(t)] = \sum_{k=0}^{n} \binom{n}{k} f^{(k)}(t) g^{(n-k)}(t)
$$

所以，
$$
\begin{align}
M_X^{(n)}(t) &= \frac{d^{n-1}}{dt^{n-1}} [K_X'(t) M_X(t)] \\
&= \sum_{m=0}^{n-1} \binom{n-1}{m} K_X^{(n-m)}(t) M_X^{(m)}(t) 
\end{align}
$$
將 $t=0$ 代入，因為 $M_X^{(0)}(0) = 1$ ，而 $M_X(t)$ 的 $n$ 階導數在 $0$ 就是動差 $\mu_n'$，我們得到：
$$
\mu_n' = \kappa_{n} + \sum_{m=1}^{n-1} \binom{n-1}{m} \kappa_{n-m} \mu_{m}'  \tag{7}\label{eq:moment_cumulant_relation}
$$
寫成矩陣形式會比較清楚：
$$
\begin{bmatrix}
\mu_1' \\
\mu_2' \\
\mu_3' \\
\mu_4' \\
\mu_5' \\
\vdots
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 & \cdots \\
\binom{1}{1} \mu_1' & 1 & 0 & 0 & 0 & \cdots \\
\binom{2}{2} \mu_2' & \binom{2}{1} \mu_1' & 1 & 0 & 0 & \cdots \\
\binom{3}{3} \mu_3' & \binom{3}{2} \mu_2' & \binom{3}{1} \mu_1' & 1 & 0 & \cdots \\
\binom{4}{4} \mu_4' & \binom{4}{3} \mu_3' & \binom{4}{2} \mu_2' & \binom{4}{1} \mu_1' & 1 & \cdots \\
\vdots & \vdots & \vdots & \vdots & \vdots & \ddots
\end{bmatrix}
\begin{bmatrix}
\kappa_1 \\
\kappa_2 \\
\kappa_3 \\
\kappa_4 \\
\kappa_5 \\
\vdots
\end{bmatrix}
$$
還是把 $\mu_n'$ 全部寫在一起好了：
$$
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 & 0 & \cdots \\
\mu_1' & 1 & 0 & 0 & 0 & 0 & \cdots \\
\mu_2' & \binom{1}{1} \mu_1' & 1 & 0 & 0 & 0 & \cdots \\
\mu_3' & \binom{2}{2} \mu_2' & \binom{2}{1} \mu_1' & 1 & 0 & 0 & \cdots \\
\mu_4' & \binom{3}{3} \mu_3' & \binom{3}{2} \mu_2' & \binom{3}{1} \mu_1' & 1 & 0 & \cdots \\
\mu_5' & \binom{4}{4} \mu_4' & \binom{4}{3} \mu_3' & \binom{4}{2} \mu_2' & \binom{4}{1} \mu_1' & 1 & \cdots \\
\vdots & \vdots & \vdots & \vdots & \vdots & \ddots
\end{bmatrix}
\begin{bmatrix}
-1 \\
\kappa_1 \\
\kappa_2 \\     
\kappa_3 \\
\kappa_4 \\
\kappa_5 \\
\vdots  
\end{bmatrix}
=
\begin{bmatrix}
-1 \\
0 \\
0 \\
0 \\
0 \\
0 \\
\vdots
\end{bmatrix}
$$
所以說要算任意的 $\kappa_n$，我們就看這個矩陣的前 $(n+1) \times (n+1)$ 子矩陣，然後套克拉瑪公式 (Cramer's Rule)。
而且因為左邊矩陣行列式為 1，所以分母總是1。比方說來算 $\kappa_5$，(最後一列是代右邊)：
$$
\kappa_5 = 
\begin{vmatrix}
1 & 0 & 0 & 0 & 0 & \textcolor{blue}{-1} \\
\mu_1' & 1 & 0 & 0 & 0 & \textcolor{blue}{0} \\
\mu_2' & \binom{2}{1} \mu_1' & 1 & 0 & 0 & \textcolor{blue}{0} \\
\mu_3' & \binom{3}{2} \mu_2' & \binom{3}{1} \mu_1' & 1 & 0 & \textcolor{blue}{0} \\
\mu_4' & \binom{4}{3} \mu_3' & \binom{4}{2} \mu_2' & \binom{4}{1} \mu_1' & 1 & \textcolor{blue}{0} \\
\mu_5' & \binom{5}{4} \mu_4' & \binom{5}{3} \mu_3' & \binom{5}{2} \mu_2' & \binom{5}{1} \mu_1' & \textcolor{blue}{0}
\end{vmatrix}
$$





